* 
* ==> Audit <==
* |--------------|------|----------|------------------|---------|---------------------|---------------------|
|   Command    | Args | Profile  |       User       | Version |     Start Time      |      End Time       |
|--------------|------|----------|------------------|---------|---------------------|---------------------|
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 24 Jan 23 23:47 IST | 24 Jan 23 23:47 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 08:53 IST |                     |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 08:53 IST | 25 Jan 23 08:53 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 13:06 IST | 25 Jan 23 13:06 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 13:06 IST | 25 Jan 23 13:06 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 13:06 IST | 25 Jan 23 13:06 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 15:05 IST | 25 Jan 23 15:05 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 15:12 IST | 25 Jan 23 15:12 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 15:18 IST |                     |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 15:18 IST | 25 Jan 23 15:18 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 15:32 IST | 25 Jan 23 15:32 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:26 IST | 25 Jan 23 18:26 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:26 IST | 25 Jan 23 18:26 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:26 IST | 25 Jan 23 18:26 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:26 IST | 25 Jan 23 18:26 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:26 IST | 25 Jan 23 18:26 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:41 IST |                     |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 18:42 IST | 25 Jan 23 18:42 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 21:28 IST | 25 Jan 23 21:28 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 25 Jan 23 21:30 IST | 25 Jan 23 21:30 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 26 Jan 23 12:17 IST | 26 Jan 23 12:17 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 26 Jan 23 12:17 IST | 26 Jan 23 12:17 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 26 Jan 23 12:42 IST | 26 Jan 23 12:42 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 26 Jan 23 12:42 IST | 26 Jan 23 12:42 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 27 Jan 23 21:56 IST | 27 Jan 23 21:56 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 27 Jan 23 22:48 IST | 27 Jan 23 22:48 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 27 Jan 23 22:48 IST | 27 Jan 23 22:48 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 10:41 IST |                     |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 10:41 IST | 28 Jan 23 10:41 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 18:29 IST | 28 Jan 23 18:29 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 18:29 IST | 28 Jan 23 18:29 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 20:56 IST | 28 Jan 23 20:56 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 20:56 IST | 28 Jan 23 20:56 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 22:32 IST | 28 Jan 23 22:32 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 22:32 IST | 28 Jan 23 22:32 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 28 Jan 23 22:33 IST | 28 Jan 23 22:33 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 29 Jan 23 17:49 IST | 29 Jan 23 17:49 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 30 Jan 23 13:05 IST | 30 Jan 23 13:05 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 30 Jan 23 13:27 IST | 30 Jan 23 13:27 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.28.0 | 30 Jan 23 13:27 IST | 30 Jan 23 13:27 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:03 IST | 30 Jan 23 17:03 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:10 IST | 30 Jan 23 17:10 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:11 IST | 30 Jan 23 17:11 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:12 IST | 30 Jan 23 17:12 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:12 IST | 30 Jan 23 17:12 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:37 IST | 30 Jan 23 17:38 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 30 Jan 23 17:38 IST |                     |
| start        |      | minikube | abhinandanwadhwa | v1.28.0 | 30 Jan 23 18:14 IST | 30 Jan 23 18:17 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 02 Feb 23 18:38 IST | 02 Feb 23 18:38 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 04 Feb 23 17:46 IST | 04 Feb 23 17:46 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 05 Feb 23 22:13 IST | 05 Feb 23 22:13 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 06 Feb 23 15:15 IST | 06 Feb 23 15:15 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 06 Feb 23 15:55 IST | 06 Feb 23 15:55 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 06 Feb 23 15:56 IST | 06 Feb 23 15:56 IST |
| update-check |      | minikube | abhinandanwadhwa | v1.29.0 | 06 Feb 23 17:59 IST | 06 Feb 23 17:59 IST |
| start        |      | minikube | abhinandanwadhwa | v1.28.0 | 06 Feb 23 19:50 IST | 06 Feb 23 19:50 IST |
| start        |      | minikube | abhinandanwadhwa | v1.28.0 | 06 Feb 23 21:14 IST |                     |
| start        |      | minikube | root             | v1.28.0 | 06 Feb 23 21:14 IST |                     |
| start        |      | minikube | root             | v1.28.0 | 06 Feb 23 21:15 IST |                     |
| start        |      | minikube | abhinandanwadhwa | v1.28.0 | 06 Feb 23 21:15 IST |                     |
|--------------|------|----------|------------------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/02/06 21:15:20
Running on machine: idk
Binary: Built with gc go1.19.3 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0206 21:15:20.233558   62130 out.go:296] Setting OutFile to fd 1 ...
I0206 21:15:20.233722   62130 out.go:348] isatty.IsTerminal(1) = true
I0206 21:15:20.233725   62130 out.go:309] Setting ErrFile to fd 2...
I0206 21:15:20.233728   62130 out.go:348] isatty.IsTerminal(2) = true
I0206 21:15:20.233824   62130 root.go:334] Updating PATH: /Users/abhinandanwadhwa/.minikube/bin
W0206 21:15:20.233929   62130 root.go:311] Error reading config file at /Users/abhinandanwadhwa/.minikube/config/config.json: open /Users/abhinandanwadhwa/.minikube/config/config.json: no such file or directory
I0206 21:15:20.234208   62130 out.go:303] Setting JSON to false
I0206 21:15:20.254355   62130 start.go:116] hostinfo: {"hostname":"idk.local","uptime":26038,"bootTime":1675672282,"procs":481,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.1","kernelVersion":"22.2.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"98996bcf-b99d-5243-b1ea-74a255796b8e"}
W0206 21:15:20.254452   62130 start.go:124] gopshost.Virtualization returned error: not implemented yet
I0206 21:15:20.260001   62130 out.go:177] üòÑ  minikube v1.28.0 on Darwin 13.1 (arm64)
I0206 21:15:20.267060   62130 notify.go:220] Checking for updates...
I0206 21:15:20.267329   62130 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0206 21:15:20.267354   62130 driver.go:365] Setting default libvirt URI to qemu:///system
I0206 21:15:20.346060   62130 docker.go:137] docker version: linux-20.10.21
I0206 21:15:20.346165   62130 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0206 21:15:20.472019   62130 info.go:266] docker info: {ID:ISR6:Y26E:QULK:Z3RC:O3OL:LCZP:EAQQ:I6PK:EU4O:KVJP:BYFH:GGPE Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:60 OomKillDisable:false NGoroutines:56 SystemTime:2023-02-06 15:45:20.392885342 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.15.49-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4124512256 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.21 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:770bd0108c32f3fb5c73ae1264f7e503fe7b2661 Expected:770bd0108c32f3fb5c73ae1264f7e503fe7b2661} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.9.1] map[Name:compose Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.13.0] map[Name:dev Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:/usr/local/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.16] map[Name:sbom Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.22.0]] Warnings:<nil>}}
I0206 21:15:20.479014   62130 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0206 21:15:20.481946   62130 start.go:282] selected driver: docker
I0206 21:15:20.481949   62130 start.go:808] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:true ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0206 21:15:20.481998   62130 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0206 21:15:20.482073   62130 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0206 21:15:20.628068   62130 info.go:266] docker info: {ID:ISR6:Y26E:QULK:Z3RC:O3OL:LCZP:EAQQ:I6PK:EU4O:KVJP:BYFH:GGPE Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:60 OomKillDisable:false NGoroutines:56 SystemTime:2023-02-06 15:45:20.537848217 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.15.49-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4124512256 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.21 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:770bd0108c32f3fb5c73ae1264f7e503fe7b2661 Expected:770bd0108c32f3fb5c73ae1264f7e503fe7b2661} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.9.1] map[Name:compose Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.13.0] map[Name:dev Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:/usr/local/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.16] map[Name:sbom Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/abhinandanwadhwa/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.22.0]] Warnings:<nil>}}
I0206 21:15:20.628415   62130 cni.go:95] Creating CNI manager for ""
I0206 21:15:20.628574   62130 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0206 21:15:20.628714   62130 start_flags.go:317] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:true ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0206 21:15:20.636008   62130 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0206 21:15:20.640499   62130 cache.go:120] Beginning downloading kic base image for docker with docker
I0206 21:15:20.643011   62130 out.go:177] üöú  Pulling base image ...
I0206 21:15:20.650966   62130 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0206 21:15:20.651005   62130 preload.go:148] Found local preload: /Users/abhinandanwadhwa/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-arm64.tar.lz4
I0206 21:15:20.651010   62130 cache.go:57] Caching tarball of preloaded images
I0206 21:15:20.651164   62130 image.go:76] Checking for gcr.io/k8s-minikube/kicbase:v0.0.36 in local docker daemon
I0206 21:15:20.651476   62130 preload.go:174] Found /Users/abhinandanwadhwa/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I0206 21:15:20.651578   62130 cache.go:60] Finished verifying existence of preloaded tar for  v1.25.3 on docker
I0206 21:15:20.651935   62130 profile.go:148] Saving config to /Users/abhinandanwadhwa/.minikube/profiles/minikube/config.json ...
I0206 21:15:20.705529   62130 image.go:80] Found gcr.io/k8s-minikube/kicbase:v0.0.36 in local docker daemon, skipping pull
I0206 21:15:20.705745   62130 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.36 exists in daemon, skipping load
I0206 21:15:20.705754   62130 cache.go:208] Successfully downloaded all kic artifacts
I0206 21:15:20.706221   62130 start.go:364] acquiring machines lock for minikube: {Name:mk6c1970411b8768fdda09958c3c427632b7f9bf Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0206 21:15:20.706298   62130 start.go:368] acquired machines lock for "minikube" in 55.542¬µs
I0206 21:15:20.706324   62130 start.go:96] Skipping create...Using existing machine configuration
I0206 21:15:20.706327   62130 fix.go:55] fixHost starting: 
I0206 21:15:20.706499   62130 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0206 21:15:20.758624   62130 fix.go:103] recreateIfNeeded on minikube: state=Running err=<nil>
W0206 21:15:20.758649   62130 fix.go:129] unexpected machine state, will restart: <nil>
I0206 21:15:20.768617   62130 out.go:177] üèÉ  Updating the running docker "minikube" container ...
I0206 21:15:20.771634   62130 machine.go:88] provisioning docker machine ...
I0206 21:15:20.771886   62130 ubuntu.go:169] provisioning hostname "minikube"
I0206 21:15:20.771942   62130 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0206 21:15:20.821939   62130 main.go:134] libmachine: Using SSH client type: native
I0206 21:15:20.822759   62130 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x100e64a30] 0x100e674d0 <nil>  [] 0s} 127.0.0.1 58993 <nil> <nil>}
I0206 21:15:20.822765   62130 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0206 21:15:20.999275   62130 main.go:134] libmachine: SSH cmd err, output: Process exited with status 1: tee: /etc/hostname: Read-only file system
minikube

I0206 21:15:20.999285   62130 machine.go:91] provisioned docker machine in 227.658625ms
I0206 21:15:21.000339   62130 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0206 21:15:21.000405   62130 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0206 21:15:21.064095   62130 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:58993 SSHKeyPath:/Users/abhinandanwadhwa/.minikube/machines/minikube/id_rsa Username:docker}
I0206 21:15:21.161442   62130 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0206 21:15:21.168147   62130 fix.go:57] fixHost completed within 461.836959ms
I0206 21:15:21.168172   62130 start.go:83] releasing machines lock for "minikube", held for 461.893167ms
W0206 21:15:21.168187   62130 start.go:603] error starting host: provision: ssh command error:
command : sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
err     : Process exited with status 1
output  : tee: /etc/hostname: Read-only file system
minikube
W0206 21:15:21.168270   62130 out.go:239] ü§¶  StartHost failed, but will try again: provision: ssh command error:
command : sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
err     : Process exited with status 1
output  : tee: /etc/hostname: Read-only file system
minikube

I0206 21:15:21.168287   62130 start.go:618] Will try again in 5 seconds ...
I0206 21:15:26.168987   62130 start.go:364] acquiring machines lock for minikube: {Name:mk6c1970411b8768fdda09958c3c427632b7f9bf Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0206 21:15:26.169181   62130 start.go:368] acquired machines lock for "minikube" in 171.583¬µs
I0206 21:15:26.169240   62130 start.go:96] Skipping create...Using existing machine configuration
I0206 21:15:26.169252   62130 fix.go:55] fixHost starting: 
I0206 21:15:26.169621   62130 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0206 21:15:26.231865   62130 fix.go:103] recreateIfNeeded on minikube: state=Running err=<nil>
W0206 21:15:26.231883   62130 fix.go:129] unexpected machine state, will restart: <nil>
I0206 21:15:26.234996   62130 out.go:177] üèÉ  Updating the running docker "minikube" container ...
I0206 21:15:26.242965   62130 machine.go:88] provisioning docker machine ...
I0206 21:15:26.242980   62130 ubuntu.go:169] provisioning hostname "minikube"
I0206 21:15:26.243054   62130 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0206 21:15:26.311932   62130 main.go:134] libmachine: Using SSH client type: native
I0206 21:15:26.312108   62130 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x100e64a30] 0x100e674d0 <nil>  [] 0s} 127.0.0.1 58993 <nil> <nil>}
I0206 21:15:26.312115   62130 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0206 21:15:26.449589   62130 main.go:134] libmachine: SSH cmd err, output: Process exited with status 1: minikube
tee: /etc/hostname: Read-only file system

I0206 21:15:26.449607   62130 machine.go:91] provisioned docker machine in 206.643667ms
I0206 21:15:26.449727   62130 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0206 21:15:26.449768   62130 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0206 21:15:26.495633   62130 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:58993 SSHKeyPath:/Users/abhinandanwadhwa/.minikube/machines/minikube/id_rsa Username:docker}
I0206 21:15:26.586604   62130 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0206 21:15:26.591639   62130 fix.go:57] fixHost completed within 422.413ms
I0206 21:15:26.591657   62130 start.go:83] releasing machines lock for "minikube", held for 422.490958ms
W0206 21:15:26.591794   62130 out.go:239] üòø  Failed to start docker container. Running "minikube delete" may fix it: provision: ssh command error:
command : sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
err     : Process exited with status 1
output  : minikube
tee: /etc/hostname: Read-only file system

I0206 21:15:26.598868   62130 out.go:177] 
W0206 21:15:26.602857   62130 out.go:239] ‚ùå  Exiting due to GUEST_PROVISION: Failed to start host: provision: ssh command error:
command : sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
err     : Process exited with status 1
output  : minikube
tee: /etc/hostname: Read-only file system

W0206 21:15:26.602865   62130 out.go:239] 
W0206 21:15:26.603624   62130 out.go:239] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    üòø  If the above advice does not help, please let us know:                             [31m‚îÇ[0m
[31m‚îÇ[0m    üëâ  https://github.com/kubernetes/minikube/issues/new/choose                           [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0206 21:15:26.613815   62130 out.go:177] 

* 
* ==> Docker <==
* -- Logs begin at Mon 2023-02-06 14:20:19 UTC, end at Mon 2023-02-06 15:45:32 UTC. --
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.218585125Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.225811750Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.226740333Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.229032958Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.229185375Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.229817041Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.230066541Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.230334041Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.230459000Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.232213541Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.232274875Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.232610500Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.232617708Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:01 minikube dockerd[633]: time="2023-02-06T15:45:01.232911208Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.366628505Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.442141255Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.493358422Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.494470922Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.495253172Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.496672297Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.496774880Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.496781630Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.498258089Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.498272130Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.498809839Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.499430297Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502027130Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502198547Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502478922Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502572672Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502661505Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502741339Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502761880Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.502493047Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.503978672Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.505312797Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:13 minikube dockerd[633]: time="2023-02-06T15:45:13.505771339Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.660262720Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.736501720Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.738205136Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.738732053Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.739034761Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.739661553Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.741092511Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.741794761Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.741913345Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.742047303Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.742329220Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.744081053Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.744263095Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.745309636Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.745760678Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.746195678Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.746553678Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.746762386Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.746933761Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.747015845Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.747534886Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.747752136Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"
Feb 06 15:45:25 minikube dockerd[633]: time="2023-02-06T15:45:25.747853095Z" level=warning msg="failed to get endpoint_count map for scope local: open /var/lib/docker/network/files/local-kv.db: read-only file system"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                              CREATED             STATE               NAME                        ATTEMPT             POD ID
6d2437cc341de       8e041a3b0ba8b                                                                                                      15 minutes ago      Running             etcd                        4                   5751a54dd21b8
b124bb67fb934       8e041a3b0ba8b                                                                                                      16 minutes ago      Exited              etcd                        3                   5751a54dd21b8
969d3c86b311a       ba04bb24b9575                                                                                                      16 minutes ago      Running             storage-provisioner         4                   983abdd635e43
b2b593daddc3b       ba04bb24b9575                                                                                                      About an hour ago   Exited              storage-provisioner         3                   983abdd635e43
3885963ad20a9       20b332c9a70d8                                                                                                      About an hour ago   Running             kubernetes-dashboard        1                   580dc1b4b65d8
ad862c360b193       a422e0e982356                                                                                                      About an hour ago   Running             dashboard-metrics-scraper   1                   b12bc3b356765
ec6883eb9f35a       e5f34edf260a7                                                                                                      About an hour ago   Running             metrics-server              1                   4500452377c44
1b2aefa688165       b19406328e70d                                                                                                      About an hour ago   Running             coredns                     1                   a397c2f951421
c6acd477b7375       213e944bbd713                                                                                                      About an hour ago   Running             controller                  1                   33d2eae629a3d
9598f12d2f2b7       bcc74496abfdb                                                                                                      About an hour ago   Running             kube-proxy                  1                   bc808cfc2b3b2
db3df925bc60b       12dd70322f973                                                                                                      About an hour ago   Running             kube-apiserver              1                   a93d6c2864a51
e1f4a2aa67361       cf6c9e4e18a33                                                                                                      About an hour ago   Running             kube-controller-manager     1                   3973268cd27f8
b55da32ff5bf0       13b15fc3e0938                                                                                                      About an hour ago   Running             kube-scheduler              1                   37fc6d982b7c3
a049a71e214b5       k8s.gcr.io/ingress-nginx/controller@sha256:5516d103a9c2ecc4f026efbd4b40662ce22dc1f824fb129ed121460aaa5c47f8        7 days ago          Exited              controller                  0                   3fd6f621a99c1
f2416005d99d9       kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c               7 days ago          Exited              dashboard-metrics-scraper   0                   c03303c99a6d8
48506e083a6e3       kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93                     7 days ago          Exited              kubernetes-dashboard        0                   a1f0405771c0b
935d4b188e8fe       k8s.gcr.io/metrics-server/metrics-server@sha256:5ddc6458eb95f5c70bd13fdab90cbd7d6ad1066e5b528ad1dcb28b76c5fb2f00   7 days ago          Exited              metrics-server              0                   79862fd31efbc
1e9cab4c49037       b19406328e70d                                                                                                      7 days ago          Exited              coredns                     0                   18a7b1ea561c0
66c7d3090cdb3       bcc74496abfdb                                                                                                      7 days ago          Exited              kube-proxy                  0                   ffbcfecad7c71
5aa0fb800aeb1       13b15fc3e0938                                                                                                      7 days ago          Exited              kube-scheduler              0                   016e186ff5ae0
77fcf2e36ffe8       cf6c9e4e18a33                                                                                                      7 days ago          Exited              kube-controller-manager     0                   c403f6bfb9e3c
d97a5bad2af73       12dd70322f973                                                                                                      7 days ago          Exited              kube-apiserver              0                   cfdc3a0825b09

* 
* ==> coredns [1b2aefa68816] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = a1b5920ef1e8e10875eeec3214b810e7e404fdaf6cfe53f31cc42ae1e9ba5884ecf886330489b6b02fba5b37a31406fcb402b2501c7ab0318fc890d74b6fae55
CoreDNS-1.9.3
linux/arm64, go1.18.2, 45b0a11

* 
* ==> coredns [1e9cab4c4903] <==
* 
* ==> describe nodes <==
* 
* ==> dmesg <==
* [  +0.020314] blk_update_request: I/O error, dev vda, sector 54827104 op 0x1:(WRITE) flags 0x800 phys_seg 1 prio class 0
[  +0.000365] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 791314 starting block 6853389)
[  +0.004575] blk_update_request: I/O error, dev vda, sector 54827112 op 0x1:(WRITE) flags 0x800 phys_seg 1 prio class 0
[  +0.000098] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 791315 starting block 6853390)
[  +0.006848] blk_update_request: I/O error, dev vda, sector 54827120 op 0x1:(WRITE) flags 0x800 phys_seg 2 prio class 0
[  +0.000098] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 791314 starting block 6853392)
[  +0.012081] blk_update_request: I/O error, dev vda, sector 54823232 op 0x1:(WRITE) flags 0x800 phys_seg 1 prio class 0
[  +0.000086] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 791315 starting block 6852905)
[  +0.005988] blk_update_request: I/O error, dev vda, sector 54823240 op 0x1:(WRITE) flags 0x800 phys_seg 2 prio class 0
[  +0.000094] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 791314 starting block 6852907)
[  +8.283259] print_req_error: 2 callbacks suppressed
[  +0.000085] blk_update_request: I/O error, dev vda, sector 62399040 op 0x1:(WRITE) flags 0x800 phys_seg 1 prio class 0
[  +0.000962] EXT4-fs warning: 2 callbacks suppressed
[  +0.000038] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1579196 starting block 7799881)
[  +0.000053] buffer_io_error: 31 callbacks suppressed
[  +0.000005] Buffer I/O error on device vda1, logical block 7799624
[Feb 6 15:30] blk_update_request: I/O error, dev vda, sector 6907904 op 0x1:(WRITE) flags 0x4000 phys_seg 125 prio class 0
[  +0.000273] blk_update_request: I/O error, dev vda, sector 6910464 op 0x1:(WRITE) flags 0x4000 phys_seg 73 prio class 0
[  +0.000190] blk_update_request: I/O error, dev vda, sector 6913024 op 0x1:(WRITE) flags 0x4000 phys_seg 59 prio class 0
[  +0.000165] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711867 starting block 864374)
[  +0.000579] blk_update_request: I/O error, dev vda, sector 6914992 op 0x1:(WRITE) flags 0x0 phys_seg 37 prio class 0
[  +0.000211] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711867 starting block 864512)
[  +0.000022] blk_update_request: I/O error, dev vda, sector 6916096 op 0x1:(WRITE) flags 0x4000 phys_seg 66 prio class 0
[  +0.000041] Buffer I/O error on device vda1, logical block 864118
[  +0.000233] Buffer I/O error on device vda1, logical block 864119
[  +0.000013] blk_update_request: I/O error, dev vda, sector 6918656 op 0x1:(WRITE) flags 0x4000 phys_seg 134 prio class 0
[  +0.000099] Buffer I/O error on device vda1, logical block 864120
[  +0.000002] Buffer I/O error on device vda1, logical block 864121
[  +0.000039] Buffer I/O error on device vda1, logical block 864122
[  +0.000488] blk_update_request: I/O error, dev vda, sector 6921216 op 0x1:(WRITE) flags 0x0 phys_seg 14 prio class 0
[  +0.000048] Buffer I/O error on device vda1, logical block 864123
[  +0.000002] Buffer I/O error on device vda1, logical block 864124
[  +0.000001] Buffer I/O error on device vda1, logical block 864125
[  +0.000001] Buffer I/O error on device vda1, logical block 864126
[  +0.000001] Buffer I/O error on device vda1, logical block 864127
[  +0.000453] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711867 starting block 865182)
[  +0.000339] blk_update_request: I/O error, dev vda, sector 6746904 op 0x1:(WRITE) flags 0x4000 phys_seg 117 prio class 0
[  +0.000183] blk_update_request: I/O error, dev vda, sector 6749464 op 0x1:(WRITE) flags 0x4000 phys_seg 135 prio class 0
[  +0.000078] blk_update_request: I/O error, dev vda, sector 6752024 op 0x1:(WRITE) flags 0x0 phys_seg 8 prio class 0
[  +0.000096] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711864 starting block 844025)
[  +0.000003] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711864 starting block 844032)
[  +0.000010] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711864 starting block 844976)
[  +0.000002] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711864 starting block 845411)
[  +0.000012] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711868 starting block 840995)
[  +0.000004] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711868 starting block 840273)
[  +0.000001] EXT4-fs warning (device vda1): ext4_end_bio:344: I/O error 10 writing to inode 1711868 starting block 840604)
[  +2.330807] Aborting journal on device vda1-8.
[  +0.000579] Buffer I/O error on dev vda1, logical block 3702784, lost sync page write
[  +0.000095] JBD2: Error -5 detected when updating journal superblock for vda1-8.
[  +0.000383] EXT4-fs error (device vda1): ext4_journal_check_start:83: comm dockerd: Detected aborted journal
[  +0.000609] Buffer I/O error on dev vda1, logical block 0, lost sync page write
[  +0.012799] EXT4-fs error (device vda1): ext4_journal_check_start:83: comm dockerd: Detected aborted journal
[  +0.000348] EXT4-fs (vda1): previous I/O error to superblock detected
[  +0.000585] EXT4-fs error (device vda1): ext4_journal_check_start:83: comm dockerd: Detected aborted journal
[  +0.000542] Buffer I/O error on dev vda1, logical block 0, lost sync page write
[  +0.000578] EXT4-fs (vda1): I/O error while writing superblock
[  +0.000114] EXT4-fs (vda1): Remounting filesystem read-only
[  +0.000011] EXT4-fs (vda1): Remounting filesystem read-only
[  +0.009835] Buffer I/O error on dev vda1, logical block 0, lost sync page write
[  +0.000531] EXT4-fs (vda1): I/O error while writing superblock

* 
* ==> etcd [6d2437cc341d] <==
* 
* ==> etcd [b124bb67fb93] <==
* 
* ==> kernel <==
*  15:45:33 up  1:40,  0 users,  load average: 0.06, 0.30, 0.56
Linux minikube 5.15.49-linuxkit #1 SMP PREEMPT Tue Sep 13 07:51:32 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.5 LTS"

* 
* ==> kube-apiserver [d97a5bad2af7] <==
* 
* ==> kube-apiserver [db3df925bc60] <==
* 
* ==> kube-controller-manager [77fcf2e36ffe] <==
* 
* ==> kube-controller-manager [e1f4a2aa6736] <==
* I0206 15:44:24.499360       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:24.502358       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:24.503004       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:24.503038       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:29.504017       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:29.505683       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:29.505964       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:29.505982       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:34.506075       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:34.507563       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:34.508883       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:34.508945       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:39.509830       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:39.511853       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:39.512446       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:39.512514       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:44.514110       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:44.515209       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:44.515752       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:44.515789       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
E0206 15:44:48.021511       1 resource_quota_controller.go:417] failed to discover resources: Get "https://192.168.49.2:8443/api": dial tcp 192.168.49.2:8443: connect: connection refused
W0206 15:44:48.021578       1 garbagecollector.go:754] failed to discover preferred resources: Get "https://192.168.49.2:8443/api": dial tcp 192.168.49.2:8443: connect: connection refused
I0206 15:44:49.517249       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:49.518685       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:49.519346       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:49.519382       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:54.520353       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:54.522425       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:54.523117       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:54.523158       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:44:59.524261       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:44:59.525689       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:44:59.526072       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:44:59.526101       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:45:04.526544       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:04.528574       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:04.529090       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:04.529162       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:45:09.530340       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:09.531901       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:09.532465       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:09.532493       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:45:14.533177       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:14.534806       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:14.535367       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:14.535410       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
E0206 15:45:18.027266       1 resource_quota_controller.go:417] failed to discover resources: Get "https://192.168.49.2:8443/api": dial tcp 192.168.49.2:8443: connect: connection refused
W0206 15:45:18.027267       1 garbagecollector.go:754] failed to discover preferred resources: Get "https://192.168.49.2:8443/api": dial tcp 192.168.49.2:8443: connect: connection refused
I0206 15:45:19.538759       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:19.540058       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:19.540404       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:19.540427       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:45:24.540693       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:24.542540       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:24.542884       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:24.542911       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.
I0206 15:45:29.543515       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
E0206 15:45:29.545792       1 node_lifecycle_controller.go:1152] Error updating node minikube: Put "https://192.168.49.2:8443/api/v1/nodes/minikube/status": dial tcp 192.168.49.2:8443: connect: connection refused
E0206 15:45:29.546271       1 node_lifecycle_controller.go:846] Failed while getting a Node to retry updating node health. Probably Node minikube was deleted.
E0206 15:45:29.546312       1 node_lifecycle_controller.go:851] Update health of Node '' from Controller error: Get "https://192.168.49.2:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused. Skipping - no pods will be evicted.

* 
* ==> kube-proxy [66c7d3090cdb] <==
* 
* ==> kube-proxy [9598f12d2f2b] <==
* I0206 14:20:39.347228       1 node.go:163] Successfully retrieved node IP: 192.168.49.2
I0206 14:20:39.347647       1 server_others.go:138] "Detected node IP" address="192.168.49.2"
I0206 14:20:39.347909       1 server_others.go:578] "Unknown proxy mode, assuming iptables proxy" proxyMode=""
I0206 14:20:39.871753       1 server_others.go:206] "Using iptables Proxier"
I0206 14:20:39.872029       1 server_others.go:213] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0206 14:20:39.872046       1 server_others.go:214] "Creating dualStackProxier for iptables"
I0206 14:20:39.875658       1 server_others.go:501] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, , defaulting to no-op detect-local for IPv6"
I0206 14:20:39.875714       1 proxier.go:262] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
I0206 14:20:39.876503       1 proxier.go:262] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
I0206 14:20:39.925922       1 server.go:661] "Version info" version="v1.25.3"
I0206 14:20:39.925961       1 server.go:663] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0206 14:20:39.932274       1 config.go:444] "Starting node config controller"
I0206 14:20:39.932292       1 shared_informer.go:255] Waiting for caches to sync for node config
I0206 14:20:39.933802       1 config.go:317] "Starting service config controller"
I0206 14:20:39.933816       1 shared_informer.go:255] Waiting for caches to sync for service config
I0206 14:20:39.933850       1 config.go:226] "Starting endpoint slice config controller"
I0206 14:20:39.934421       1 shared_informer.go:255] Waiting for caches to sync for endpoint slice config
I0206 14:20:40.132858       1 shared_informer.go:262] Caches are synced for service config
I0206 14:20:40.133085       1 shared_informer.go:262] Caches are synced for node config
I0206 14:20:40.133495       1 shared_informer.go:262] Caches are synced for endpoint slice config

* 
* ==> kube-scheduler [5aa0fb800aeb] <==
* 
* ==> kube-scheduler [b55da32ff5bf] <==
* I0206 14:20:33.446822       1 serving.go:348] Generated self-signed cert in-memory
W0206 14:20:35.203023       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0206 14:20:35.203061       1 authentication.go:346] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0206 14:20:35.203070       1 authentication.go:347] Continuing without authentication configuration. This may treat all requests as anonymous.
W0206 14:20:35.203075       1 authentication.go:348] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0206 14:20:35.230455       1 server.go:148] "Starting Kubernetes Scheduler" version="v1.25.3"
I0206 14:20:35.230563       1 server.go:150] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0206 14:20:35.232560       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0206 14:20:35.232582       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0206 14:20:35.232582       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0206 14:20:35.232673       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0206 14:20:35.333719       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Logs begin at Mon 2023-02-06 14:20:19 UTC, end at Mon 2023-02-06 15:45:33 UTC. --
Feb 06 15:45:11 minikube kubelet[1161]: E0206 15:45:11.960839    1161 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-minikube.174145d8cb1678fd", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"23290", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-minikube", UID:"bd8b8fe30652798a5ae3fc51e66ef681", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.February, 6, 15, 28, 53, 0, time.Local), LastTimestamp:time.Date(2023, time.February, 6, 15, 30, 21, 801988343, time.Local), Count:19, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events/kube-apiserver-minikube.174145d8cb1678fd": dial tcp 192.168.49.2:8443: connect: connection refused'(may retry after sleeping)
Feb 06 15:45:13 minikube kubelet[1161]: E0206 15:45:13.201937    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"backend\" with ImagePullBackOff: \"Back-off pulling image \\\"abhinandan1311/devcode-backend\\\"\"" pod="default/backend-846665757-hsj9b" podUID=82dd8aa0-a649-4881-bf10-47495df797b3
Feb 06 15:45:16 minikube kubelet[1161]: E0206 15:45:16.831417    1161 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s": dial tcp 192.168.49.2:8443: connect: connection refused
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.747808    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?resourceVersion=0&timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.748965    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.749725    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.750687    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.751412    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:18 minikube kubelet[1161]: E0206 15:45:18.751470    1161 kubelet_node_status.go:447] "Unable to update node status" err="update node status exceeds retry count"
Feb 06 15:45:19 minikube kubelet[1161]: E0206 15:45:19.204898    1161 kuberuntime_manager.go:862] container &Container{Name:etcd,Image:registry.k8s.io/etcd:3.5.4-0,Command:[etcd --advertise-client-urls=https://192.168.49.2:2379 --cert-file=/var/lib/minikube/certs/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/minikube/etcd --experimental-initial-corrupt-check=true --experimental-watch-progress-notify-interval=5s --initial-advertise-peer-urls=https://192.168.49.2:2380 --initial-cluster=minikube=https://192.168.49.2:2380 --key-file=/var/lib/minikube/certs/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.49.2:2380 --name=minikube --peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/var/lib/minikube/certs/etcd/peer.key --peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt --proxy-refresh-interval=70000 --snapshot-count=10000 --trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{104857600 0} {<nil>} 100Mi BinarySI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:etcd-data,ReadOnly:false,MountPath:/var/lib/minikube/etcd,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:etcd-certs,ReadOnly:false,MountPath:/var/lib/minikube/certs/etcd,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/health?exclude=NOSPACE&serializable=true,Port:{0 2381 },Host:127.0.0.1,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:8,TerminationGracePeriodSeconds:nil,},ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/health?serializable=false,Port:{0 2381 },Host:127.0.0.1,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:24,TerminationGracePeriodSeconds:nil,},} start failed in pod etcd-minikube_kube-system(bd495b7643dfc9d3194bd002e968bc3d): CreateContainerConfigError: open /var/lib/kubelet/pods/bd495b7643dfc9d3194bd002e968bc3d/etc-hosts: read-only file system
Feb 06 15:45:19 minikube kubelet[1161]: E0206 15:45:19.205077    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"etcd\" with CreateContainerConfigError: \"open /var/lib/kubelet/pods/bd495b7643dfc9d3194bd002e968bc3d/etc-hosts: read-only file system\"" pod="kube-system/etcd-minikube" podUID=bd495b7643dfc9d3194bd002e968bc3d
Feb 06 15:45:20 minikube kubelet[1161]: E0206 15:45:20.209571    1161 kuberuntime_manager.go:862] container &Container{Name:kubernetes-dashboard,Image:docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93,Command:[],Args:[--namespace=kubernetes-dashboard --enable-skip-login --disable-settings-authorizer],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:9090,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:tmp-volume,ReadOnly:false,MountPath:/tmp,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-kkvgb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/,Port:{0 9090 },Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:30,TimeoutSeconds:30,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:3,TerminationGracePeriodSeconds:nil,},ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:*1001,RunAsNonRoot:nil,ReadOnlyRootFilesystem:*true,AllowPrivilegeEscalation:*false,RunAsGroup:*2001,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kubernetes-dashboard-57bbdc5f89-ddz9f_kubernetes-dashboard(ad8b9172-8742-49ce-be17-1cd973e1e49e): CreateContainerConfigError: open /var/lib/kubelet/pods/ad8b9172-8742-49ce-be17-1cd973e1e49e/etc-hosts: read-only file system
Feb 06 15:45:20 minikube kubelet[1161]: E0206 15:45:20.209644    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kubernetes-dashboard\" with CreateContainerConfigError: \"open /var/lib/kubelet/pods/ad8b9172-8742-49ce-be17-1cd973e1e49e/etc-hosts: read-only file system\"" pod="kubernetes-dashboard/kubernetes-dashboard-57bbdc5f89-ddz9f" podUID=ad8b9172-8742-49ce-be17-1cd973e1e49e
Feb 06 15:45:21 minikube kubelet[1161]: W0206 15:45:21.122834    1161 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Feb 06 15:45:21 minikube kubelet[1161]: W0206 15:45:21.124128    1161 machine.go:65] Cannot read vendor id correctly, set empty.
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.197869    1161 status_manager.go:667] "Failed to get status for pod" podUID=dd40b3d9-47de-49a3-96dc-72ac669dc8d0 pod="kube-system/coredns-565d847f94-dfrqk" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/coredns-565d847f94-dfrqk\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198089    1161 status_manager.go:667] "Failed to get status for pod" podUID=46086a7f-940c-4151-a871-f3ecaea4c123 pod="kube-system/metrics-server-769cd898cd-4ktpf" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/metrics-server-769cd898cd-4ktpf\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198253    1161 status_manager.go:667] "Failed to get status for pod" podUID=69170bb6-b775-4575-95c6-0031f511496f pod="kubernetes-dashboard/dashboard-metrics-scraper-b74747df5-6hx9s" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kubernetes-dashboard/pods/dashboard-metrics-scraper-b74747df5-6hx9s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198371    1161 status_manager.go:667] "Failed to get status for pod" podUID=bd8b8fe30652798a5ae3fc51e66ef681 pod="kube-system/kube-apiserver-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-apiserver-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198480    1161 status_manager.go:667] "Failed to get status for pod" podUID=d8a4b9f9-0b7a-464b-91c4-3f6ece6ecb46 pod="default/backend-846665757-lpfv5" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-lpfv5\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198590    1161 status_manager.go:667] "Failed to get status for pod" podUID=8a9e4053-7124-4c8e-99be-929c51cc1047 pod="ingress-nginx/ingress-nginx-controller-5959f988fd-6cnv6" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/ingress-nginx/pods/ingress-nginx-controller-5959f988fd-6cnv6\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198722    1161 status_manager.go:667] "Failed to get status for pod" podUID=82dd8aa0-a649-4881-bf10-47495df797b3 pod="default/backend-846665757-hsj9b" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-hsj9b\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.198830    1161 status_manager.go:667] "Failed to get status for pod" podUID=17e15e34-8ac6-4b15-be47-574b2496729e pod="default/backend-846665757-rnc7t" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-rnc7t\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.199003    1161 status_manager.go:667] "Failed to get status for pod" podUID=91c789ffd31943242ef457881ac1824a pod="kube-system/kube-controller-manager-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-controller-manager-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.200529    1161 status_manager.go:667] "Failed to get status for pod" podUID=ad8b9172-8742-49ce-be17-1cd973e1e49e pod="kubernetes-dashboard/kubernetes-dashboard-57bbdc5f89-ddz9f" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kubernetes-dashboard/pods/kubernetes-dashboard-57bbdc5f89-ddz9f\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.399767    1161 status_manager.go:667] "Failed to get status for pod" podUID=92dee923-716c-4ee0-bfdb-43577a4e2d23 pod="kube-system/kube-proxy-n7hjp" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-proxy-n7hjp\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: I0206 15:45:21.600752    1161 status_manager.go:667] "Failed to get status for pod" podUID=7e6ece94cd0950fdbbf66ddae1e4c53b pod="kube-system/kube-scheduler-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-scheduler-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:21 minikube kubelet[1161]: E0206 15:45:21.965974    1161 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-minikube.174145d8cb1678fd", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"23290", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-minikube", UID:"bd8b8fe30652798a5ae3fc51e66ef681", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.February, 6, 15, 28, 53, 0, time.Local), LastTimestamp:time.Date(2023, time.February, 6, 15, 30, 21, 801988343, time.Local), Count:19, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events/kube-apiserver-minikube.174145d8cb1678fd": dial tcp 192.168.49.2:8443: connect: connection refused'(may retry after sleeping)
Feb 06 15:45:23 minikube kubelet[1161]: E0206 15:45:23.205894    1161 kuberuntime_manager.go:862] container &Container{Name:kube-apiserver,Image:registry.k8s.io/kube-apiserver:v1.25.3,Command:[kube-apiserver --advertise-address=192.168.49.2 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/var/lib/minikube/certs/ca.crt --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=8443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/minikube/certs/sa.pub --service-account-signing-key-file=/var/lib/minikube/certs/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/var/lib/minikube/certs/apiserver.crt --tls-private-key-file=/var/lib/minikube/certs/apiserver.key],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{cpu: {{250 -3} {<nil>} 250m DecimalSI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:ca-certs,ReadOnly:true,MountPath:/etc/ssl/certs,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:etc-ca-certificates,ReadOnly:true,MountPath:/etc/ca-certificates,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:k8s-certs,ReadOnly:true,MountPath:/var/lib/minikube/certs,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:usr-local-share-ca-certificates,ReadOnly:true,MountPath:/usr/local/share/ca-certificates,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:usr-share-ca-certificates,ReadOnly:true,MountPath:/usr/share/ca-certificates,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/livez,Port:{0 8443 },Host:192.168.49.2,Scheme:HTTPS,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:8,TerminationGracePeriodSeconds:nil,},ReadinessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/readyz,Port:{0 8443 },Host:192.168.49.2,Scheme:HTTPS,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:0,TimeoutSeconds:15,PeriodSeconds:1,SuccessThreshold:1,FailureThreshold:3,TerminationGracePeriodSeconds:nil,},Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/livez,Port:{0 8443 },Host:192.168.49.2,Scheme:HTTPS,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:24,TerminationGracePeriodSeconds:nil,},} start failed in pod kube-apiserver-minikube_kube-system(bd8b8fe30652798a5ae3fc51e66ef681): CreateContainerConfigError: open /var/lib/kubelet/pods/bd8b8fe30652798a5ae3fc51e66ef681/etc-hosts: read-only file system
Feb 06 15:45:23 minikube kubelet[1161]: E0206 15:45:23.206096    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CreateContainerConfigError: \"open /var/lib/kubelet/pods/bd8b8fe30652798a5ae3fc51e66ef681/etc-hosts: read-only file system\"" pod="kube-system/kube-apiserver-minikube" podUID=bd8b8fe30652798a5ae3fc51e66ef681
Feb 06 15:45:23 minikube kubelet[1161]: E0206 15:45:23.834783    1161 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s": dial tcp 192.168.49.2:8443: connect: connection refused
Feb 06 15:45:24 minikube kubelet[1161]: E0206 15:45:24.204205    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"backend\" with ImagePullBackOff: \"Back-off pulling image \\\"abhinandan1311/devcode-backend\\\"\"" pod="default/backend-846665757-hsj9b" podUID=82dd8aa0-a649-4881-bf10-47495df797b3
Feb 06 15:45:25 minikube kubelet[1161]: E0206 15:45:25.206631    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"backend\" with ImagePullBackOff: \"Back-off pulling image \\\"abhinandan1311/devcode-backend\\\"\"" pod="default/backend-846665757-rnc7t" podUID=17e15e34-8ac6-4b15-be47-574b2496729e
Feb 06 15:45:25 minikube kubelet[1161]: E0206 15:45:25.209068    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"backend\" with ImagePullBackOff: \"Back-off pulling image \\\"abhinandan1311/devcode-backend\\\"\"" pod="default/backend-846665757-lpfv5" podUID=d8a4b9f9-0b7a-464b-91c4-3f6ece6ecb46
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.909937    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?resourceVersion=0&timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.910202    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.910362    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.910475    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.910581    1161 kubelet_node_status.go:460] "Error updating node status, will retry" err="error getting node \"minikube\": Get \"https://control-plane.minikube.internal:8443/api/v1/nodes/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:28 minikube kubelet[1161]: E0206 15:45:28.910597    1161 kubelet_node_status.go:447] "Unable to update node status" err="update node status exceeds retry count"
Feb 06 15:45:30 minikube kubelet[1161]: E0206 15:45:30.661660    1161 webhook.go:154] Failed to make webhook authenticator request: Post "https://control-plane.minikube.internal:8443/apis/authentication.k8s.io/v1/tokenreviews": dial tcp 192.168.49.2:8443: connect: connection refused
Feb 06 15:45:30 minikube kubelet[1161]: E0206 15:45:30.662046    1161 server.go:291] "Unable to authenticate the request due to an error" err="Post \"https://control-plane.minikube.internal:8443/apis/authentication.k8s.io/v1/tokenreviews\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:30 minikube kubelet[1161]: E0206 15:45:30.836727    1161 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s": dial tcp 192.168.49.2:8443: connect: connection refused
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.196461    1161 status_manager.go:667] "Failed to get status for pod" podUID=dd40b3d9-47de-49a3-96dc-72ac669dc8d0 pod="kube-system/coredns-565d847f94-dfrqk" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/coredns-565d847f94-dfrqk\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.197959    1161 status_manager.go:667] "Failed to get status for pod" podUID=46086a7f-940c-4151-a871-f3ecaea4c123 pod="kube-system/metrics-server-769cd898cd-4ktpf" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/metrics-server-769cd898cd-4ktpf\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.198634    1161 status_manager.go:667] "Failed to get status for pod" podUID=69170bb6-b775-4575-95c6-0031f511496f pod="kubernetes-dashboard/dashboard-metrics-scraper-b74747df5-6hx9s" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kubernetes-dashboard/pods/dashboard-metrics-scraper-b74747df5-6hx9s\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.198989    1161 status_manager.go:667] "Failed to get status for pod" podUID=bd8b8fe30652798a5ae3fc51e66ef681 pod="kube-system/kube-apiserver-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-apiserver-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.199644    1161 status_manager.go:667] "Failed to get status for pod" podUID=d8a4b9f9-0b7a-464b-91c4-3f6ece6ecb46 pod="default/backend-846665757-lpfv5" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-lpfv5\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.199851    1161 status_manager.go:667] "Failed to get status for pod" podUID=8a9e4053-7124-4c8e-99be-929c51cc1047 pod="ingress-nginx/ingress-nginx-controller-5959f988fd-6cnv6" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/ingress-nginx/pods/ingress-nginx-controller-5959f988fd-6cnv6\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.200032    1161 status_manager.go:667] "Failed to get status for pod" podUID=82dd8aa0-a649-4881-bf10-47495df797b3 pod="default/backend-846665757-hsj9b" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-hsj9b\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.200183    1161 status_manager.go:667] "Failed to get status for pod" podUID=17e15e34-8ac6-4b15-be47-574b2496729e pod="default/backend-846665757-rnc7t" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/backend-846665757-rnc7t\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.200332    1161 status_manager.go:667] "Failed to get status for pod" podUID=91c789ffd31943242ef457881ac1824a pod="kube-system/kube-controller-manager-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-controller-manager-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.200497    1161 status_manager.go:667] "Failed to get status for pod" podUID=ad8b9172-8742-49ce-be17-1cd973e1e49e pod="kubernetes-dashboard/kubernetes-dashboard-57bbdc5f89-ddz9f" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kubernetes-dashboard/pods/kubernetes-dashboard-57bbdc5f89-ddz9f\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: E0206 15:45:31.201408    1161 kuberuntime_manager.go:862] container &Container{Name:kubernetes-dashboard,Image:docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93,Command:[],Args:[--namespace=kubernetes-dashboard --enable-skip-login --disable-settings-authorizer],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:9090,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:tmp-volume,ReadOnly:false,MountPath:/tmp,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-kkvgb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/,Port:{0 9090 },Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:30,TimeoutSeconds:30,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:3,TerminationGracePeriodSeconds:nil,},ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:*1001,RunAsNonRoot:nil,ReadOnlyRootFilesystem:*true,AllowPrivilegeEscalation:*false,RunAsGroup:*2001,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kubernetes-dashboard-57bbdc5f89-ddz9f_kubernetes-dashboard(ad8b9172-8742-49ce-be17-1cd973e1e49e): CreateContainerConfigError: open /var/lib/kubelet/pods/ad8b9172-8742-49ce-be17-1cd973e1e49e/etc-hosts: read-only file system
Feb 06 15:45:31 minikube kubelet[1161]: E0206 15:45:31.201517    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kubernetes-dashboard\" with CreateContainerConfigError: \"open /var/lib/kubelet/pods/ad8b9172-8742-49ce-be17-1cd973e1e49e/etc-hosts: read-only file system\"" pod="kubernetes-dashboard/kubernetes-dashboard-57bbdc5f89-ddz9f" podUID=ad8b9172-8742-49ce-be17-1cd973e1e49e
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.396435    1161 status_manager.go:667] "Failed to get status for pod" podUID=92dee923-716c-4ee0-bfdb-43577a4e2d23 pod="kube-system/kube-proxy-n7hjp" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-proxy-n7hjp\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: I0206 15:45:31.598805    1161 status_manager.go:667] "Failed to get status for pod" podUID=7e6ece94cd0950fdbbf66ddae1e4c53b pod="kube-system/kube-scheduler-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-scheduler-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Feb 06 15:45:31 minikube kubelet[1161]: E0206 15:45:31.967169    1161 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-minikube.174145d8cb1678fd", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"23290", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-minikube", UID:"bd8b8fe30652798a5ae3fc51e66ef681", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.February, 6, 15, 28, 53, 0, time.Local), LastTimestamp:time.Date(2023, time.February, 6, 15, 30, 21, 801988343, time.Local), Count:19, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events/kube-apiserver-minikube.174145d8cb1678fd": dial tcp 192.168.49.2:8443: connect: connection refused'(may retry after sleeping)
Feb 06 15:45:33 minikube kubelet[1161]: E0206 15:45:33.205003    1161 kuberuntime_manager.go:862] container &Container{Name:etcd,Image:registry.k8s.io/etcd:3.5.4-0,Command:[etcd --advertise-client-urls=https://192.168.49.2:2379 --cert-file=/var/lib/minikube/certs/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/minikube/etcd --experimental-initial-corrupt-check=true --experimental-watch-progress-notify-interval=5s --initial-advertise-peer-urls=https://192.168.49.2:2380 --initial-cluster=minikube=https://192.168.49.2:2380 --key-file=/var/lib/minikube/certs/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.49.2:2380 --name=minikube --peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/var/lib/minikube/certs/etcd/peer.key --peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt --proxy-refresh-interval=70000 --snapshot-count=10000 --trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{104857600 0} {<nil>} 100Mi BinarySI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:etcd-data,ReadOnly:false,MountPath:/var/lib/minikube/etcd,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:etcd-certs,ReadOnly:false,MountPath:/var/lib/minikube/certs/etcd,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/health?exclude=NOSPACE&serializable=true,Port:{0 2381 },Host:127.0.0.1,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:8,TerminationGracePeriodSeconds:nil,},ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/health?serializable=false,Port:{0 2381 },Host:127.0.0.1,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:15,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:24,TerminationGracePeriodSeconds:nil,},} start failed in pod etcd-minikube_kube-system(bd495b7643dfc9d3194bd002e968bc3d): CreateContainerConfigError: open /var/lib/kubelet/pods/bd495b7643dfc9d3194bd002e968bc3d/etc-hosts: read-only file system
Feb 06 15:45:33 minikube kubelet[1161]: E0206 15:45:33.205051    1161 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"etcd\" with CreateContainerConfigError: \"open /var/lib/kubelet/pods/bd495b7643dfc9d3194bd002e968bc3d/etc-hosts: read-only file system\"" pod="kube-system/etcd-minikube" podUID=bd495b7643dfc9d3194bd002e968bc3d

* 
* ==> kubernetes-dashboard [3885963ad20a] <==
* 
* ==> kubernetes-dashboard [48506e083a6e] <==
* 
* ==> storage-provisioner [969d3c86b311] <==
* E0206 15:42:18.745126       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:21.347467       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:25.388002       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:29.728177       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:32.238662       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:34.294811       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:38.565665       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:40.792193       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:44.345132       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:47.096228       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:50.175074       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:53.345857       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:55.546409       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:42:59.160318       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:02.122174       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:06.285943       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:10.622820       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:13.398186       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:16.611946       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:19.576505       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:21.625446       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:25.174646       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:28.205383       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:31.024056       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:35.155585       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:37.724561       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:41.562306       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:43.650895       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:47.398335       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:50.903931       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:54.146722       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:43:56.323284       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:00.067057       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:04.181437       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:08.535425       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:12.572269       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:16.576801       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:19.177662       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:23.372171       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:25.556091       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:29.563538       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:33.080432       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:36.887428       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:40.406814       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:42.640784       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:44.679907       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:48.086329       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:50.256936       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:54.658421       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:44:58.220614       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:02.587471       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:06.597653       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:09.397579       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:12.986709       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:17.289437       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:20.038701       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:22.487724       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:26.811001       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:30.814724       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused
E0206 15:45:33.559329       1 leaderelection.go:325] error retrieving resource lock kube-system/k8s.io-minikube-hostpath: Get "https://10.96.0.1:443/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath": dial tcp 10.96.0.1:443: connect: connection refused

* 
* ==> storage-provisioner [b2b593daddc3] <==
